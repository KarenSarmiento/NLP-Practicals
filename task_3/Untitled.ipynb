{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/karen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.porter import *\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09090909090909091"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('drop.n.01').path_similarity(wn.synset('droplet.n.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('droplet.n.01').path_similarity(wn.synset('drop.v.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['', 'all', u'distanc', 'shot', 'reservoir', 'when', 'over', 'coathanger.', 'not', u'touch', 'cold', 'still', 'up,', 'hold', u'depend', 'system', u'activ', 'to', 'moulex', 'position.', 'wool', 'curtains.', 'important:', 'it.', 'D', 'soon', u'regularli', u'temperatur', 'five', u'press', 'empty.', 'silk', '40g', u'success', u'wash', u'button', 'item', 'adjust', u'integr', 'steam', u'scorch', 'set', 'we', u'procedur', u'coathang', 'therefore,', u'design', 'second.', 'worn,', 'maximum.', 'close', 'maximum,', u'time', 'out', 'for', u'goe', 'avoid', u'abl', 'per', 'intensity.', 'creases.', u'be', 'C', 'month).', 'given', 'water', 'spray', 'auto-clean', u'vertic', 'super', 'by', u'addit', u'continu', 'on', 'last', u'suffici', 'of', 'auto-clean.', 'turn', 'amount', 'however,', 'out,', 'iron.', 'and', 'thermostat', 'low.', 'one', 'down', u'distil', '(1-2', 'times.', u'visibl', 'your', 'risk', u'use', 'or', 'from', 'fabric', 'jet', 'temperature.', 'two', u'empti', 'too', u'suit', 'type', 'until', 'more', 'function', 'steam,', 'B', u'desir', 'that', 'needed.', 'but', u'ani', u'cloth', 'heat', 'attempt', u'ha', 'than', 'ironed.', 'steam.', 'and,', u'fur', u'possibl', u'remov', 'maximum', 'will', 'calcium', 'can', 'iron', u'posit', 'etc.', 'control', u'creas', 'tap', u'give', 'use.', 'is', 'in', 'it', u'indic', 'an', 'as', 'at', 'have', 'water.', u'momentarili', u'doe', 'sink,', 'if', 'Do', 'F', '-', u'alway', u'unintent', 'which', u'advis', 'instead', 'you', u'fill', 'A', 'E', u'thi', 'reservoir.', 'can,', 'after', 'upon', u'befor', u'intens', u'veri', 'unplug', u'becom', 'a', u'droplet', 'off', 'longer', 'light', 'It', u'produc', 'As', 'without', 'so', u'deposit', u'allow', 'In', 'the', 'order', 'If'])\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "YOUR MOULEX IRON\n",
    "A Filling the reservoir\n",
    "Your iron is designed to function using tap\n",
    "water. However, it will last longer if you use\n",
    "distilled water.\n",
    "- Always unplug the iron before filling the\n",
    "reservoir.\n",
    "- Always empty the reservoir after use.\n",
    "B Temperature and steam control\n",
    "Your Moulex iron has two buttons which\n",
    "control the intensity of heat produced by the\n",
    "iron. You can, therefore, adjust the\n",
    "temperature of the iron and the amount of\n",
    "steam being given off depending upon the\n",
    "type of fabric being ironed.\n",
    "- Turn the steam control to the desired\n",
    "intensity.\n",
    "- Turn the thermostat control to the desired\n",
    "temperature.\n",
    "Important: If your iron produces droplets of\n",
    "water instead of giving off steam, your\n",
    "temperature control is set too low.\n",
    "C Spray button\n",
    "This button activates a jet of cold water which\n",
    "allows you to iron out any unintentional\n",
    "creases. Press the button for one second.\n",
    "D Pressing button\n",
    "This button activates a super shot of steam\n",
    "which momentarily gives you an additional 40g\n",
    "of steam when needed.\n",
    "Important: Do not use this more than five\n",
    "successive times.\n",
    "E Suits etc.\n",
    "It is possible to use this iron in a vertical\n",
    "position so that you can remove creases from\n",
    "clothes on coathangers or from curtains.\n",
    "Turning the thermostat control and the steam\n",
    "button to maximum, hold the iron in a vertical\n",
    "position close to the fabric but without\n",
    "touching it. Hold down the pressing button for\n",
    "a maximum of one second. The steam\n",
    "produced is not always visible but is still able\n",
    "to remove creases.\n",
    "Important: Hold the iron at a sufficient\n",
    "distance from silk and wool to avoid all risk of\n",
    "scorching Do not attempt to remove creases\n",
    "from an item of clothing that is being worn,\n",
    "always use a coathanger.\n",
    "F Auto-clean\n",
    "In order that your iron does not become furred\n",
    "up, Moulex have integrated an auto-clean\n",
    "system and we advise you to use it very\n",
    "regularly (1-2 times per month).\n",
    "- Turn the steam control to the off position.\n",
    "- Fill the reservoir and turn the thermostat\n",
    "control to maximum.\n",
    "- As soon as the indicator light goes out,\n",
    "unplug the iron and, holding it over the sink,\n",
    "turn the steam control to auto-clean. Any\n",
    "calcium deposits will be washed out by the\n",
    "steam. Continue the procedure until the\n",
    "reservoir is empty.\n",
    "\"\"\".split(\"\\n\")\n",
    "text_actual = []\n",
    "for word in text:\n",
    "    text_actual.extend(word.split(\" \"))\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "text_actual = [stemmer.stem(val) for val in text_actual]\n",
    "text = set(text_actual)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('shed.v.01.shed'): False\n",
      "Lemma('dropper.n.01.dropper'): False\n",
      "Lemma('devolve.v.03.degenerate'): False\n",
      "Lemma('recuperate.v.04.recuperate'): False\n",
      "Lemma('drop.n.03.fall'): False\n",
      "Lemma('drop_curtain.n.01.drop_curtain'): False\n",
      "Lemma('expending.n.01.expending'): False\n",
      "Lemma('cliff.n.01.drop-off'): False\n",
      "Lemma('neglect.v.01.pretermit'): False\n",
      "Lemma('spender.n.03.spender'): False\n",
      "Lemma('omission.n.04.omission'): False\n",
      "Lemma('lumberman.n.01.feller'): False\n",
      "Lemma('flatten.v.03.flatten'): False\n",
      "Lemma('swing.n.04.swinging'): False\n",
      "Lemma('neglecter.n.01.neglecter'): False\n",
      "Lemma('neglect.v.01.miss'): False\n",
      "Lemma('attend_to.v.01.attend_to'): False\n",
      "Lemma('expensive.a.01.expensive'): False\n",
      "Lemma('shed.v.01.shake_off'): False\n",
      "Lemma('shed.v.01.throw_away'): False\n",
      "Lemma('devolve.v.03.devolve'): False\n",
      "Lemma('shed.v.01.throw_off'): False\n",
      "Lemma('spending.n.01.spending'): False\n",
      "Lemma('dismiss.v.03.send_packing'): False\n",
      "Lemma('dangle.v.01.dangle'): False\n",
      "Lemma('shed.v.01.cast_off'): False\n",
      "Lemma('drop.n.01.pearl'): False\n",
      "Lemma('fell.v.01.strike_down'): False\n",
      "Lemma('pretermission.n.01.pretermission'): False\n",
      "Lemma('shed.v.01.throw'): False\n",
      "Lemma('fell.v.01.cut_down'): False\n",
      "Lemma('neglect.v.01.overlook'): False\n",
      "Lemma('sharpen.v.06.sharpen'): False\n",
      "Lemma('degenerative.s.01.degenerative'): False\n",
      "Lemma('devolve.v.03.deteriorate'): False\n",
      "Lemma('drop_curtain.n.01.drop_cloth'): False\n",
      "Lemma('dismiss.v.03.dismiss'): False\n",
      "Lemma('spender.n.03.expender'): False\n",
      "Lemma('omissible.s.01.omissible'): False\n",
      "Lemma('dangle.v.01.swing'): False\n",
      "Lemma('drop.v.08.put_down'): False\n",
      "Lemma('sink.v.01.drop_down'): False\n",
      "Lemma('outgo.n.01.expenditure'): False\n",
      "Lemma('sink.v.01.sink'): False\n",
      "Lemma('drop.v.08.set_down'): False\n",
      "Lemma('drop.n.01.bead'): False\n",
      "Lemma('drop.v.08.discharge'): False\n",
      "Lemma('dribble.v.02.dribble'): False\n",
      "Lemma('cliff.n.01.cliff'): False\n",
      "Lemma('droplet.n.01.droplet'): True\n",
      "Lemma('spend.v.02.expend'): False\n",
      "Lemma('drop.v.07.knock_off'): False\n",
      "Lemma('drop.n.02.driblet'): False\n",
      "Lemma('dismiss.v.03.send_away'): False\n",
      "Lemma('drop.v.08.unload'): False\n",
      "Lemma('beady.s.01.beady'): False\n",
      "Lemma('drop.v.08.drop_off'): False\n",
      "Lemma('drop.n.01.drop'): False\n",
      "Lemma('dribble.v.02.drip'): False\n",
      "Lemma('neglect.v.01.neglect'): False\n",
      "Lemma('shed.v.01.cast'): False\n",
      "Lemma('neglect.v.01.leave_out'): False\n",
      "Lemma('fell.v.01.fell'): False\n",
      "Lemma('neglect.v.01.overleap'): False\n",
      "Lemma('deterioration.n.01.deterioration'): False\n",
      "Lemma('drop.n.03.free_fall'): False\n",
      "Lemma('neglect.v.01.omit'): False\n",
      "Lemma('degeneracy.n.01.degeneration'): False\n",
      "Lemma('drop.n.03.dip'): False\n",
      "Lemma('spend.v.02.spend'): False\n",
      "Lemma('omissive.a.01.omissive'): False\n",
      "Lemma('drop.n.02.drib'): False\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "# Find hypernym for all of these synets?\n",
    "wn.synsets('drop')\n",
    "\n",
    "# Terms in different syntactic categories that have the same root form and are semantically related.\n",
    "wn.synsets('drop')[1].lemmas()[0].derivationally_related_forms()\n",
    "\n",
    "\n",
    "\n",
    "def find_similar_words(word):\n",
    "    similar_words = set()\n",
    "    for synset in wn.synsets(word):\n",
    "        for lemmas in synset.lemmas():\n",
    "            similar_words.add(lemmas)\n",
    "    #         print(lemmas.derivationally_related_forms())\n",
    "            for related in lemmas.derivationally_related_forms():\n",
    "                similar_words.add(related)\n",
    "\n",
    "            for related in lemmas.hypernyms():\n",
    "                similar_words.add(related)\n",
    "\n",
    "            for related in lemmas.hyponyms():\n",
    "                similar_words.add(related)\n",
    "\n",
    "            for related in lemmas.antonyms():\n",
    "                similar_words.add(related)\n",
    "\n",
    "    for word in similar_words:\n",
    "        print(\"{}: {}\".format(word, stemmer.stem(word.name()) in text))\n",
    "\n",
    "    print(len(similar_words))\n",
    "find_similar_words('drop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_methods(object, spacing=20): \n",
    "    methodList = [] \n",
    "    for method_name in dir(object): \n",
    "        try: \n",
    "            if callable(getattr(object, method_name)): \n",
    "                methodList.append(str(method_name)) \n",
    "        except: \n",
    "            methodList.append(str(method_name)) \n",
    "            processFunc = (lambda s: ' '.join(s.split())) or (lambda s: s) \n",
    "    for method in methodList: \n",
    "        try: \n",
    "            print(str(method.ljust(spacing)) + ' ' + \n",
    "              processFunc(str(getattr(object, method).__doc__)[0:90])) \n",
    "        except: \n",
    "            print(method.ljust(spacing) + ' ' + ' getattr() failed') \n",
    "\n",
    "\n",
    "get_methods(wn.synsets('drop')[1].lemmas()[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5, Synset('give_birth.v.01')), (0.5, Synset('droplet.n.01')), (0.5, Synset('displace.v.03')), (0.5, Synset('depository.n.01')), (0.3333333333333333, Synset('wholly.r.01')), (0.3333333333333333, Synset('wash.v.09')), (0.3333333333333333, Synset('wash.v.04')), (0.3333333333333333, Synset('use.v.03')), (0.3333333333333333, Synset('use.v.01')), (0.3333333333333333, Synset('unhorse.v.01')), (0.3333333333333333, Synset('unaccented.s.02')), (0.3333333333333333, Synset('two.s.01')), (0.3333333333333333, Synset('turn.v.19')), (0.3333333333333333, Synset('turn.v.16')), (0.3333333333333333, Synset('turn.v.10')), (0.3333333333333333, Synset('turn.v.07')), (0.3333333333333333, Synset('turn.v.04')), (0.3333333333333333, Synset('touch.v.11')), (0.3333333333333333, Synset('touch.v.05')), (0.3333333333333333, Synset('touch.v.01'))]\n",
      "[(2.9444389791664407, Synset('droplet.n.01')), (2.9444389791664407, Synset('depository.n.01')), (2.5649493574615367, Synset('give_birth.v.01')), (2.5649493574615367, Synset('displace.v.03')), (2.538973871058276, Synset('touch.n.06')), (2.538973871058276, Synset('spray.n.02')), (2.538973871058276, Synset('set.n.11')), (2.538973871058276, Synset('nip.n.01')), (2.538973871058276, Synset('amount.n.02')), (2.2512917986064953, Synset('water_system.n.02')), (2.2512917986064953, Synset('measure.n.02')), (2.159484249353372, Synset('wash.v.09')), (2.159484249353372, Synset('wash.v.04')), (2.159484249353372, Synset('use.v.03')), (2.159484249353372, Synset('use.v.01')), (2.159484249353372, Synset('unhorse.v.01')), (2.159484249353372, Synset('turn.v.19')), (2.159484249353372, Synset('turn.v.16')), (2.159484249353372, Synset('turn.v.10')), (2.159484249353372, Synset('turn.v.07'))]\n"
     ]
    }
   ],
   "source": [
    "path_similarities = []\n",
    "lch_similarities = []\n",
    "\n",
    "for drop_syn in wn.synsets('drop'):\n",
    "    for word in text:\n",
    "        for syn in wn.synsets(word):\n",
    "            path_similarities.append((drop_syn.path_similarity(syn), syn))\n",
    "            try:\n",
    "                lch_similarities.append((drop_syn.lch_similarity(syn), syn))\n",
    "            except:\n",
    "                pass\n",
    "path_similarities.sort(reverse=True)  \n",
    "lch_similarities.sort(reverse=True)  \n",
    "print(path_similarities[:20])\n",
    "print(lch_similarities[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "DeprecationWarning",
     "evalue": "Deprecated. Use gensim.models.KeyedVectors.load_word2vec_format instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeprecationWarning\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-7b2d6f4c6784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1298\u001b[0m             limit=None, datatype=REAL):\n\u001b[1;32m   1299\u001b[0m         \u001b[0;34m\"\"\"Deprecated. Use :meth:`gensim.models.KeyedVectors.load_word2vec_format` instead.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Deprecated. Use gensim.models.KeyedVectors.load_word2vec_format instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDeprecationWarning\u001b[0m: Deprecated. Use gensim.models.KeyedVectors.load_word2vec_format instead."
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
